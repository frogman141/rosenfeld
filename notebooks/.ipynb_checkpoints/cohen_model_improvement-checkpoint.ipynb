{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import re\n",
    "import plotly \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Importing all of the models I am going to try and improve cancer detection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing relavent data\n",
    "gene_data = pd.read_csv('../data/cohen_S5.csv')\n",
    "protein_data = pd.read_csv('../data/cohen_S6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data processing functions that maybe reused later on\n",
    "def convert_to_numbers(rec):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for converting all of the columns that pandas dtypes object. Typically,\n",
    "        these columns are measuring protein concentrations into a float numerical value. This function extracts numbers\n",
    "        via regular expressions and the combines them and convert them into a float data type.\n",
    "    \"\"\"\n",
    "    digit = 0\n",
    "    if type(rec) is str:\n",
    "        pre_decimal = ''\n",
    "        digits = re.findall('\\d+', rec)\n",
    "        for indx, num in enumerate(digits):\n",
    "            if (indx + 1) != len(digits):\n",
    "                pre_decimal = pre_decimal + num\n",
    "            else:\n",
    "                digit = '.'.join([pre_decimal, num])\n",
    "    else:\n",
    "        digit = rec\n",
    "    return float(digit)\n",
    "\n",
    "def conversion(df, skip_col, conv_col, func=convert_to_numbers):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for looping through select columns a pandas dataframe for further \n",
    "        processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in conv_col:\n",
    "    \n",
    "        if col in skip_col:\n",
    "            continue\n",
    "\n",
    "        df[col] = df[col].apply(func)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Storing Data\n",
    "\n",
    "In the following sections of code I am preprocessing the raw and caching it back in the raw data files initially loaded. Specifically, I am converting columns that contain numerical but are a string data type into float numerical data types. To do this I am reusing the functions conversion and convert_to_numbers intitial developed the visualiation_of_cohen notebook.\n",
    "\n",
    "\n",
    "## Do not rerun following cells. As I have already cleaned the data. If you do you erase most of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skip_gene_cols = ['Patient ID #', 'Sample ID #', 'Tumor type', 'AJCC Stage',\n",
    "       'Plasma volume (mL)', 'Plasma DNA concentration (ng/mL)',\n",
    "       'Mutation identified in plasma*', 'Î© score',\n",
    "       'Mutant allele frequency (%)',\n",
    "       'CancerSEEK Logistic Regression Score', 'CancerSEEK Test Result']\n",
    "\n",
    "gene_data = conversion(gene_data, skip_gene_cols, [' Mutant fragments/mL plasma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protein_skip_cols = ['Patient ID #', 'Sample ID #', 'Tumor type', 'AJCC Stage', 'AXL (pg/ml)', 'sPECAM-1 (pg/ml)', 'TIMP-2 (pg/ml)', 'CancerSEEK Logistic Regression Score', 'CancerSEEK Test Result']\n",
    "protein_data = conversion(protein_data, protein_skip_cols, protein_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protein_data.to_csv('../data/cohen_S6.csv', index=False)\n",
    "gene_data.to_csv('../data/cohen_S5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Processing\n",
    "\n",
    "Here is where I begin to merge datasets into a usuable dataframe that can be utilized in model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a lable encoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "# merging gene and protein dataframes\n",
    "merged = pd.concat([protein_data, gene_data.iloc[:,4:-2]], axis=1)\n",
    "merged['AJCC Stage'] = merged['AJCC Stage'].fillna('normal')\n",
    "merged = merged.fillna(0)\n",
    "\n",
    "# grab the target names for Mutli-Class Classification models\n",
    "merged[\"Tumor encoded\"] = lb_make.fit_transform(merged['Tumor type'])\n",
    "merged = merged.sort_values(by=['Tumor encoded'])\n",
    "# binning cancers and normal into bins for Binary Classification models \n",
    "y_bin = []\n",
    "for row in merged['AJCC Stage'].values:\n",
    "    if 'normal' in row:\n",
    "        y_bin.append(0)\n",
    "    else:\n",
    "        y_bin.append(1)\n",
    "y_bin = np.array(y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating reusable functions\n",
    "def feature_extract(df, multi_features, std=False):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for extracting the features were modeling with from a source \n",
    "        Pandas Dataframe. This is a achieved by looping through all of the feature lists were extracting from\n",
    "        \n",
    "        Inputs:\n",
    "            - df: a souce pandas dataframe that contains all of the columns of the features parameter\n",
    "            - multi_features: a python list of list that contains a series of columns that are extracted from the df \n",
    "            parameter.\n",
    "            - std: a boolean parameter that tells the function to standardize the data or not\n",
    "        \n",
    "        Ouputs:\n",
    "            - features_df: a pandas dataframe from extracting the features that are being used to develop\n",
    "            models\n",
    "    \"\"\"\n",
    "    all_features_df = []\n",
    "    \n",
    "    for features in multi_features:\n",
    "        if std:\n",
    "            features_df = StandardScaler().fit_transform(df[features])\n",
    "        else:\n",
    "            features_df = df[features]\n",
    "        \n",
    "        all_features_df.append(features_df)\n",
    "\n",
    "    return all_features_df\n",
    "\n",
    "def multi_dataset_training(model, datasets, y_target, cv_iter=10, show_median=False):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible training multiple versions of the same model with different datasets. \n",
    "        To do this the function loops through a list of datasets (either numpy array or pandas Dataframe) and trains \n",
    "        the model via Cross-Validation. The results of this training is then stored and returned in a python list.\n",
    "        \n",
    "        Inputs:\n",
    "            - model: a Scikit learning model class (i.e. LogisticRegression or Perceptron)\n",
    "            - datasets: a python list of datasets that are either a numpy array or pandas dataframe.\n",
    "            - y_target: a numpy array that contains the records labelled class\n",
    "            - cv_iter: number of times Cross-Validation will iterate.\n",
    "            - show_median: a boolean value that tells the function to print the median test score.\n",
    "        \n",
    "        Ouputs:\n",
    "            - cv_results : a python list of values returned by the Scikit-Learn cross_validate function.\n",
    "    \"\"\"\n",
    "    cv_results = []\n",
    "    for X_data in datasets:\n",
    "        result = cross_validate(model, X_data, y_target, cv=cv_iter, return_train_score=False)\n",
    "        \n",
    "        if show_median:\n",
    "            print (median(result['test_score']))\n",
    "        \n",
    "        cv_results.append(result)\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts to improve Cancer Detection via Binary Classification\n",
    "\n",
    "In the following sections of code I am exploring methods of improving model accuracy. These methods include utilizing novel features, standardizing the data, and training different types of models. All of these sections are reusing the functions above and are using Machine Learning models that were imported from the Scikit-Learn Library.\n",
    "\n",
    "**Current Models being trained:**\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Perceptron\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a serious of dataframes that contain different individual features.\n",
    "# The five dataframes utilizing different data features for model training\n",
    "# created are: base, mutant_frags, dna_cont, mutant_alleles, all\n",
    "base_features = ['CA-125 (U/ml)', 'CEA (pg/ml)', 'CA19-9 (U/ml)', 'Prolactin (pg/ml)', 'HGF (pg/ml)', \n",
    "                  'OPN (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)', 'Î© score']\n",
    "mutant_frags_features = ['CA-125 (U/ml)', 'CEA (pg/ml)', 'CA19-9 (U/ml)', 'Prolactin (pg/ml)', 'HGF (pg/ml)', \n",
    "                  'OPN (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)', 'Î© score', ' Mutant fragments/mL plasma']\n",
    "dna_cont_features = ['CA-125 (U/ml)', 'CEA (pg/ml)', 'CA19-9 (U/ml)', 'Prolactin (pg/ml)', 'HGF (pg/ml)', \n",
    "                  'OPN (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)', 'Î© score', 'Plasma DNA concentration (ng/mL)']\n",
    "mutant_allele_features =  ['CA-125 (U/ml)', 'CEA (pg/ml)', 'CA19-9 (U/ml)', 'Prolactin (pg/ml)', 'HGF (pg/ml)', \n",
    "                  'OPN (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)', 'Î© score', 'Mutant allele frequency (%)']\n",
    "\n",
    "all_features = ['CA-125 (U/ml)', 'CEA (pg/ml)', 'CA19-9 (U/ml)', 'Prolactin (pg/ml)', 'HGF (pg/ml)', \n",
    "                'OPN (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)', 'Î© score', ' Mutant fragments/mL plasma', \n",
    "                'Plasma DNA concentration (ng/mL)', 'Mutant allele frequency (%)']\n",
    "\n",
    "cols_to_extract = [base_features, all_features, dna_cont_features, mutant_allele_features, mutant_frags_features]\n",
    "datasets_nonstd = feature_extract(merged, cols_to_extract)\n",
    "datasets_std = feature_extract(merged, cols_to_extract, std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with standardized data\n",
      "0.8540161495962602\n",
      "0.8595106550907656\n",
      "0.8540161495962602\n",
      "0.8540009714042863\n",
      "0.8540161495962602\n",
      "\n",
      "Training Logistic Regression with non standardized data\n",
      "0.6308511930058891\n",
      "0.6225487219962358\n",
      "0.6170542165017303\n",
      "0.6281039402586364\n",
      "0.6418402039949\n"
     ]
    }
   ],
   "source": [
    "# initializing the base logistic regression model\n",
    "print ('Training Logistic Regression with standardized data')\n",
    "log_reg_std_results = multi_dataset_training(LogisticRegression(), datasets_std, y_bin, show_median=True)\n",
    "print ('\\nTraining Logistic Regression with non standardized data')\n",
    "log_reg_nonstd_results = multi_dataset_training(LogisticRegression(), datasets_nonstd, y_bin, show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precptron with standardized data\n",
      "0.8370165745856353\n",
      "0.8456985003946329\n",
      "0.8539706150203388\n",
      "0.8314917127071824\n",
      "0.8480662983425414\n",
      "\n",
      "Training Precptron with non-standardized data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5683060109289617\n",
      "0.5683060109289617\n",
      "0.5683060109289617\n",
      "0.5683060109289617\n",
      "0.5683060109289617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initializing and training a perceptron model\n",
    "print ('Training Precptron with standardized data')\n",
    "precptron_std_results = multi_dataset_training(Perceptron(), datasets_std, y_bin, show_median=True)\n",
    "print ('\\nTraining Precptron with non-standardized data')\n",
    "precptron_nonstd_results = multi_dataset_training(Perceptron(), datasets_nonstd, y_bin,show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scv with standardized data\n",
      "0.8292149839111165\n",
      "0.8540161495962602\n",
      "0.8512688968490074\n",
      "0.834709489405622\n",
      "0.8292149839111165\n",
      "\n",
      "Training scv with non-standardized data\n",
      "0.5524861878453039\n",
      "0.5524861878453039\n",
      "0.5524861878453039\n",
      "0.5524861878453039\n",
      "0.5524861878453039\n"
     ]
    }
   ],
   "source": [
    "# initializing the base scv model\n",
    "print ('Training scv with standardized data')\n",
    "scv_std_results = multi_dataset_training(SVC(), datasets_std, y_bin, show_median=True)\n",
    "print ('\\nTraining scv with non-standardized data')\n",
    "scv_nonstd_results = multi_dataset_training(SVC(), datasets_nonstd, y_bin,show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decision tree with standardized data\n",
      "0.8232044198895028\n",
      "0.8370165745856354\n",
      "0.8099690364883735\n",
      "0.8214285714285714\n",
      "0.8093922651933702\n",
      "\n",
      "Training decision tree with non-standardized data\n",
      "0.8259668508287292\n",
      "0.8209125129014632\n",
      "0.8121546961325967\n",
      "0.8264829093558375\n",
      "0.8209428692854107\n"
     ]
    }
   ],
   "source": [
    "# tree = DecisionTreeClassifier()\n",
    "# initializing the base decision tree model\n",
    "print ('Training decision tree with standardized data')\n",
    "scv_std_results = multi_dataset_training(DecisionTreeClassifier(), datasets_std, y_bin, show_median=True)\n",
    "print ('\\nTraining decision tree with non-standardized data')\n",
    "scv_nonstd_results = multi_dataset_training(DecisionTreeClassifier(), datasets_nonstd, y_bin,show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest with standardized data\n",
      "0.8784530386740331\n",
      "0.8870590735231618\n",
      "0.8701657458563536\n",
      "0.8977900552486188\n",
      "0.8674033149171271\n",
      "\n",
      "Training random forest with non-standardized data\n",
      "0.8870438953311881\n",
      "0.8787414243215348\n",
      "0.8867403314917126\n",
      "0.8729281767955801\n",
      "0.8870438953311881\n"
     ]
    }
   ],
   "source": [
    "# forest = RandomForestClassifier()\n",
    "# initializing the base random forest model\n",
    "print ('Training random forest with standardized data')\n",
    "forest_std_results = multi_dataset_training(RandomForestClassifier(), datasets_std, y_bin, show_median=True)\n",
    "print ('\\nTraining random forest with non-standardized data')\n",
    "forest_nonstd_results = multi_dataset_training(RandomForestClassifier(), datasets_nonstd, y_bin,show_median=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts to improve Predictive Tissue Localization\n",
    "\n",
    "In the following sections of code I am exploring methods of improving model accuracy in predicting tissue localization of cancers. In this section I am utilizing a multitude of different methods of modeling in attempt to improve the overall accuracy of this model.\n",
    "\n",
    "**Current Models being trained:**\n",
    "- Support Vector Machine\n",
    "- Perceptron\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tissue_local_features = ['AFP (pg/ml)', 'Angiopoietin-2 (pg/ml)', 'AXL (pg/ml)', 'CA-125 (U/ml)',\n",
    "       'CA 15-3 (U/ml)', 'CA19-9 (U/ml)', 'CD44 (ng/ml)', 'CEA (pg/ml)',\n",
    "       'CYFRA 21-1 (pg/ml)', 'DKK1 (ng/ml)', 'Endoglin (pg/ml)',\n",
    "       'FGF2 (pg/ml)', 'Follistatin (pg/ml)', 'Galectin-3 (ng/ml)',\n",
    "       'G-CSF (pg/ml)', 'GDF15 (ng/ml)', 'HE4 (pg/ml)', 'HGF (pg/ml)',\n",
    "       'IL-6 (pg/ml)', 'IL-8 (pg/ml)', 'Kallikrein-6 (pg/ml)',\n",
    "       'Leptin (pg/ml)', 'Mesothelin (ng/ml)', 'Midkine (pg/ml)',\n",
    "       'Myeloperoxidase (ng/ml)', 'NSE (ng/ml)', 'OPG (ng/ml)', 'OPN (pg/ml)',\n",
    "       'PAR (pg/ml)', 'Prolactin (pg/ml)', 'sEGFR (pg/ml)', 'sFas (pg/ml)',\n",
    "       'SHBG (nM)', 'sHER2/sEGFR2/sErbB2 (pg/ml)', 'sPECAM-1 (pg/ml)',\n",
    "       'TGFa (pg/ml)', 'Thrombospondin-2 (pg/ml)', 'TIMP-1 (pg/ml)',\n",
    "       'TIMP-2 (pg/ml)','Î© score']\n",
    "\n",
    "# grab the target names for Mutli-Class Classification models\n",
    "# Additionally, I am removing all of the normal cases since \n",
    "# there reported False Postive rate was 7 out of 812\n",
    "normal_remove = merged[merged['Tumor type'] != 'Normal'].sort_values(by=['Tumor encoded'])\n",
    "normal_remove = normal_remove[normal_remove['CancerSEEK Test Result'] != 'Negative']\n",
    "y_cancer = normal_remove[\"Tumor encoded\"].values\n",
    "\n",
    "# extracting of the features utilized by Cohen et al. 2018 to predict tissue localization\n",
    "cancer_data_nonstd = feature_extract(normal_remove, [tissue_local_features])\n",
    "cancer_data_std = feature_extract(normal_remove, [tissue_local_features], std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scv with standardized data\n",
      "0.5403225806451613\n",
      "\n",
      "Training scv with non-standardized data\n",
      "0.4032258064516129\n"
     ]
    }
   ],
   "source": [
    "# initializing the base scv model\n",
    "print ('Training scv with standardized data')\n",
    "scv_std_results = multi_dataset_training(SVC(), cancer_data_std, y_cancer, show_median=True)\n",
    "print ('\\nTraining scv with non-standardized data')\n",
    "scv_nonstd_results = multi_dataset_training(SVC(), cancer_data_nonstd, y_cancer, show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGDClassifier with standardized data\n",
      "0.4526209677419355\n",
      "\n",
      "Training SGDClassifier with non-standardized data\n",
      "0.3172883064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initializing and training a perceptron model\n",
    "print ('Training SGDClassifier with standardized data')\n",
    "precptron_std_results = multi_dataset_training(SGDClassifier(), cancer_data_std, y_cancer, show_median=True)\n",
    "print ('\\nTraining SGDClassifier with non-standardized data')\n",
    "precptron_nonstd_results = multi_dataset_training(SGDClassifier(), cancer_data_nonstd, y_cancer, show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decision tree with standardized data\n",
      "0.4838709677419355\n",
      "\n",
      "Training decision tree with non-standardized data\n",
      "0.47631048387096775\n"
     ]
    }
   ],
   "source": [
    "# initializing the base decision tree model\n",
    "print ('Training decision tree with standardized data')\n",
    "tree_std_results = multi_dataset_training(DecisionTreeClassifier(), cancer_data_std, y_cancer, show_median=True)\n",
    "print ('\\nTraining decision tree with non-standardized data')\n",
    "tree_nonstd_results = multi_dataset_training(DecisionTreeClassifier(), cancer_data_nonstd, y_cancer, show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest with standardized data\n",
      "0.6048387096774194\n",
      "\n",
      "Training random forest with non-standardized data\n",
      "0.5846586738438952\n"
     ]
    }
   ],
   "source": [
    "# initializing the base random forest model\n",
    "print ('Training random forest with standardized data')\n",
    "forest_std_results = multi_dataset_training(RandomForestClassifier(), cancer_data_std, y_cancer, show_median=True)\n",
    "print ('\\nTraining random forest with non-standardized data')\n",
    "forest_nonstd_results = multi_dataset_training(RandomForestClassifier(), cancer_data_std, y_cancer, show_median=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multi-Layer Perceptron (MLP) with standardized data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6059701492537313\n",
      "\n",
      "Training Multi-Layer Perceptron (MLP) with non-standardized data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5983870967741935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbaker/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "# intiailizing and training Multi-Layer Perceptron (MLP)\n",
    "print ('Training Multi-Layer Perceptron (MLP) with standardized data')\n",
    "mlp_std_results = multi_dataset_training(MLPClassifier(), cancer_data_std, y_cancer, show_median=True)\n",
    "print ('\\nTraining Multi-Layer Perceptron (MLP) with non-standardized data')\n",
    "mlp_nonstd_results = multi_dataset_training(MLPClassifier(), cancer_data_std, y_cancer, show_median=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts to Optimize Best Performing Modelings with Dimensionality Reducing Algorithms\n",
    "\n",
    "After trying PCA and TSNE it appears that they have a negative affect on overall model accuracy. As such i am not going to pursue them any longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_std = PCA(n_components=8).fit_transform(datasets_std[0])\n",
    "bin_nonstd = PCA(n_components=8).fit_transform(datasets_nonstd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest with standardized data\n",
      "0.8098779673365308\n",
      "\n",
      "Training random forest with non-standardized data\n",
      "0.7768653997935766\n",
      "Training Logistic Regression with standardized data\n",
      "0.8540161495962602\n",
      "\n",
      "Training Logistic Regression with non standardized data\n",
      "0.781767955801105\n"
     ]
    }
   ],
   "source": [
    "# initializing the Random Forest model\n",
    "print ('Training random forest with standardized data')\n",
    "forest_std_results = multi_dataset_training(RandomForestClassifier(), [bin_std], y_bin, show_median=True)\n",
    "print ('\\nTraining random forest with non-standardized data')\n",
    "forest_nonstd_results = multi_dataset_training(RandomForestClassifier(), [bin_nonstd], y_bin,show_median=True)\n",
    "# initializing the base logistic regression model\n",
    "print ('Training Logistic Regression with standardized data')\n",
    "log_reg_std_results = multi_dataset_training(LogisticRegression(), [bin_std], y_bin, show_median=True)\n",
    "print ('\\nTraining Logistic Regression with non standardized data')\n",
    "log_reg_nonstd_results = multi_dataset_training(LogisticRegression(), [bin_nonstd], y_bin, show_median=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Model Metrics for Top Performing models:\n",
    "\n",
    "After retraining the origin models used by Cohen et al 2018 and training novel models I've idenified that Logistic Regression and Random Forest models perform the best (in the case of the Random Forest it performs the best in both cases). With these top performing models were going to generate a confusion matrix of their performance. A confusion matrix evaluates the quality of the output of a classification model. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions. (Derived from the Scikit-Learn Confusion Matrix tutorial: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)\n",
    "\n",
    "Models being Evalutated:\n",
    "- Random Forest\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "\n",
    "def train_model_gen_cm(model, X, y, classes, cv_iter=10, title='Confusion matrix', figname='test-image.png'):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for training a model with cross-validation and getting it's the\n",
    "        predictions back. With these predictions and y (data labels) a confusion matrix is generated, plotted, \n",
    "        and saved to a png file.\n",
    "        \n",
    "        Inputs:\n",
    "            - model: A scikit learn machine learning model that needs to be trained.\n",
    "            - X: a pandas dataframe or numpy array that contains all of the data features were going to use\n",
    "            to train the model.\n",
    "            - y: an array that contains the true class labels for each record in X.\n",
    "            - classes: the string label of all of the classes being trained on in the model.\n",
    "            - cv_iter: number of cross-validation iterations\n",
    "            - title: title of the confusion matrix graph\n",
    "            - figname: file name of the figure being generated\n",
    "        \n",
    "        Outputs:\n",
    "            - predicted_scores: model predictions\n",
    "            - cm: 2D Numpy array with confusion matrix values.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_scores = cross_val_predict(model, X, y, cv=cv_iter)\n",
    "    cm = confusion_matrix(y, predicted_scores)\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes, normalize=True, title=title)\n",
    "    plt.savefig(fname=figname)\n",
    "    \n",
    "    return predicted_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracting the basic feature datasets and creating\n",
    "basic_df_std = datasets_std[0]\n",
    "basic_df_nonstd = datasets_nonstd[0]\n",
    "# cancer_df_std = cancer_data_std[0]\n",
    "# cancer_df_nonstd = cancer_data_nonstd[0]\n",
    "\n",
    "# # grabbing the class types\n",
    "# cancer_types = normal_remove['Tumor type'].unique()\n",
    "bin_types = ['healthy', 'cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.88546798 0.11453202]\n",
      " [0.21393035 0.78606965]]\n",
      "Normalized confusion matrix\n",
      "[[0.8817734  0.1182266 ]\n",
      " [0.19900498 0.80099502]]\n",
      "Normalized confusion matrix\n",
      "[[0.87684729 0.12315271]\n",
      " [0.22686567 0.77313433]]\n",
      "Normalized confusion matrix\n",
      "[[0.24753695 0.75246305]\n",
      " [0.08159204 0.91840796]]\n"
     ]
    }
   ],
   "source": [
    "# generating confusion matrix for Logistic Regression Model\n",
    "log_reg_std_l1 = train_model_gen_cm(LogisticRegression(penalty='l1'), basic_df_std, y_bin, bin_types, title='Logistic Reg Binary Std', figname='Log-Reg-Std-l1.png')\n",
    "log_reg_nonstd_l1 = train_model_gen_cm(LogisticRegression(penalty='l1'), basic_df_nonstd, y_bin, bin_types, title='Logistic Reg Binary NonStd', figname='Log-Reg-NonStd-l1.png')\n",
    "log_reg_std_l2 = train_model_gen_cm(LogisticRegression(), basic_df_std, y_bin, bin_types, title='Logistic Reg Binary Std', figname='Log-Reg-Std-l2.png')\n",
    "log_reg_nonstd_l2 = train_model_gen_cm(LogisticRegression(), basic_df_nonstd, y_bin, bin_types, title='Logistic Reg Binary NonStd', figname='Log-Reg-NonStd-l2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.87068966 0.12931034]\n",
      " [0.13532338 0.86467662]]\n",
      "Normalized confusion matrix\n",
      "[[0.87315271 0.12684729]\n",
      " [0.13930348 0.86069652]]\n"
     ]
    }
   ],
   "source": [
    "forest_pred = train_model_gen_cm(RandomForestClassifier(), basic_df_std, y_bin, bin_types, title='Forest Binary Std', figname='Forest-Binary-Std.png')\n",
    "var = train_model_gen_cm(RandomForestClassifier(), basic_df_nonstd, y_bin, bin_types, title='Forest Binary NonStd', figname='Forest-Binary-NonStd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cancer_df_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e22e6857ec42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model_gen_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancer_df_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cancer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Forest Localize Std'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Forest-Localize-Std.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_model_gen_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancer_df_nonstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cancer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Forest Localize NonStd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Forest-Localize-NonStd.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cancer_df_std' is not defined"
     ]
    }
   ],
   "source": [
    "train_model_gen_cm(RandomForestClassifier(), cancer_df_std, y_cancer, cancer_types, title='Forest Localize Std', figname='Forest-Localize-Std.png')\n",
    "train_model_gen_cm(RandomForestClassifier(), cancer_df_nonstd, y_cancer, cancer_types, title='Forest Localize NonStd', figname='Forest-Localize-NonStd.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Performance of improved CancerSEEK Models\n",
    "\n",
    "Here i am taking the results of my initially improved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged['log_reg_pred'] = log_reg_std_l2\n",
    "merged['forets_pred'] = forest_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_by_cancer(pred_values, true_value):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for calculating binary classification models accuracy per\n",
    "        cancer type. We to this by adding up the correct predicitions and dividing it by the total number\n",
    "        of patients with that cancer.\n",
    "        \n",
    "        Inputs:\n",
    "            - pred_values: a list of the predicted values\n",
    "            - true_value: the correct binary classification for pred_values to be compared to\n",
    "        \n",
    "        Output:\n",
    "            - % correct: calculating the % of patients we correctly predicted.\n",
    "    \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = len(pred_values)\n",
    "    \n",
    "    for rec in pred_values:\n",
    "        if rec == true_value:\n",
    "            correct += 1\n",
    "        \n",
    "    return correct / total\n",
    "\n",
    "def gen_bar_chart(x, y, df, filename, fig_title, hue_col='model', rotate=True, show_fig=True):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for generating a bargraph and rotating the x lables 45 degrees. After\n",
    "        it generates the barplot it'll be default show the use the figure and then save the figure to file.\n",
    "        \n",
    "        Inputs:\n",
    "            - x: column name for x axis values\n",
    "            - y: column name for y axis values\n",
    "            - filename: file name for the file were generating\n",
    "            - hue_col: a string value identifying the column that the hue will be based off of.\n",
    "            - show_fig: a boolean values for determining whether or not to show the figure.\n",
    "            - rotate: a boolean value that determines whether to rotate x-axis or not.\n",
    "        \n",
    "        Outputs:\n",
    "            - a seaborn barplot is generated by this function\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    bar_chart = sns.barplot(x=x, y=y, hue=hue_col, data=df)\n",
    "    \n",
    "    if rotate:\n",
    "        for item in bar_chart.get_xticklabels():\n",
    "            item.set_rotation(45)\n",
    "        \n",
    "    plt.title(fig_title)\n",
    "    plt.savefig(fname=filename)\n",
    "    \n",
    "    if show_fig:\n",
    "        plt.show()\n",
    "\n",
    "def custom_groupby(df, group_col, cancers=[], pre_dev_model_accuracy=[], model_name=[], current_name='Baker'):\n",
    "    \"\"\"\n",
    "        Overview: This function is responsible for extracting accuracy of a cancer stage or type via custom groupby\n",
    "        method. We group the pandas dataframe by the column of interest (Tumor type or AJCC Stage) and then loop \n",
    "        through these groups. If the group is for healthy patients skip. This function returns a pandas dataframe\n",
    "        that contains the accuracy of logistic regression and random forest models.\n",
    "        \n",
    "        Input:\n",
    "            - df: a pandas dataframe that contains model accuracy information\n",
    "            - group_col: a string that specifies the col were running the pandas groubpy method on.\n",
    "            - cancers: this parameter allows a user to pass cancer type or stage label information for external \n",
    "              model data.\n",
    "            - pre_dev_model_accuracy: a python list contianing model accuracy's per cancer stage or type for an \n",
    "              external model\n",
    "            - model_name: a python list containing string values that label what model an accuracy comes from\n",
    "            - current_name: a string value informing us which model generated data were working with. Default value\n",
    "            is Baker because I am working with my own model.\n",
    "        \n",
    "        Output:\n",
    "            - a pandas dataframe that contains all model accuracy per groub_col unique value.\n",
    "    \"\"\"\n",
    "    log_accuracy = pre_dev_model_accuracy[:]\n",
    "    forest_accuracy = pre_dev_model_accuracy[:]\n",
    "    group = df.groupby([group_col])\n",
    "    \n",
    "    for indx, tumor_type in group:\n",
    "        \n",
    "        if 'normal' in indx.lower():\n",
    "            continue\n",
    "        \n",
    "        forest = accuracy_by_cancer(tumor_type['forets_pred'].values, 1)\n",
    "        log = accuracy_by_cancer(tumor_type['log_reg_pred'].values, 1)\n",
    "        \n",
    "        cancers.append(indx)\n",
    "        log_accuracy.append(log)\n",
    "        forest_accuracy.append(forest)\n",
    "        model_name.append(current_name)\n",
    "    \n",
    "    return pd.DataFrame.from_dict({\"Log Accuracy\": log_accuracy, 'Forest Accuracy': forest_accuracy, \n",
    "                                   group_col: cancers, 'model': model_name})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing cohen et al. 2018 model performance data from Fig 2. For comparison with personally improved model\n",
    "cohen_name = ['Cohen']\n",
    "cohen_types = ['Ovary', 'Liver','Stomach', 'Pancreas', 'Esophagus', 'Colorectum', 'Lung', 'Breast']\n",
    "cohen_types_accuracy = [0.99, 0.98, 0.72, 0.72, 0.68, 0.65, 0.58, 0.33]\n",
    "cohen_stages = ['I', 'II', 'III']\n",
    "cohen_stages_accuracy = [0.42, 0.75, 0.78]\n",
    "\n",
    "# calculating and storing accuracy by cancer type for binary classification models\n",
    "# (Logistic Regression and Random Forest) for cancer detection\n",
    "cancer_type = custom_groupby(merged, 'Tumor type', cohen_types, cohen_types_accuracy, (cohen_name * 8))\n",
    "cancer_stage = custom_groupby(merged, 'AJCC Stage', cohen_stages, cohen_stages_accuracy, (cohen_name * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AJCC Stage</th>\n",
       "      <th>Forest Accuracy</th>\n",
       "      <th>Log Accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>cohen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>II</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>cohen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>III</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>cohen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>0.829146</td>\n",
       "      <td>0.713568</td>\n",
       "      <td>Baker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>II</td>\n",
       "      <td>0.855131</td>\n",
       "      <td>0.782696</td>\n",
       "      <td>Baker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>III</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>Baker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AJCC Stage  Forest Accuracy  Log Accuracy  model\n",
       "0          I         0.420000      0.420000  cohen\n",
       "1         II         0.750000      0.750000  cohen\n",
       "2        III         0.780000      0.780000  cohen\n",
       "3          I         0.829146      0.713568  Baker\n",
       "4         II         0.855131      0.782696  Baker\n",
       "5        III         0.902913      0.796117  Baker"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAIVCAYAAADI5GYOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xu8ZXP9+PHX28wwLuM6o8IwFLnn\nMuQWauR+q1TkkuTSL7qRShdUUl/07ZtSUd+UkKRIIso1vuRScgmRBhMxxv3OeP/++HzO2I4zM+fM\nnD377DWv5+NxHmfvtdZe+7322nu91+eyPisyE0mS1P3m6XQAkiRpcJjUJUlqCJO6JEkNYVKXJKkh\nTOqSJDWESV2SpIYwqWtQRURGxJs6HcfcJCI+HxE/6nQc3SIiDoyI49r8Hj+KiM/PwutWiIin2hHT\nUBYRwyLiqYhYdhDWdW5EvHMw4upGJvUOiYiJEbFFp+OY0yJiq4i4IiKejIjJEXF5ROzY6bhmJCKO\njIgXa8xPRsQ/IuK7EfGGAaxjUPZ3RGweEZNap2Xm0Zm57+yuu4/32jsiptaD7VMRcXdE/L9ZWM/b\nWtbxdD3xe6rlb7YP5AOIZT7g88Bx9fmbImLQB+vIzH0z8+h+xDMpIjZved3dmbnQQN8vIvZt2VeP\nR8RfI2Kbga6nUzJzamYulJn3DsLqvgEcNQjr6Uom9YaLiOGdjqFHROwC/BI4BVgGeB1wOLBDJ+Nq\nNYPP6xeZOQpYHHgX8HrghoEk9i51dT3YLgTsAhwTEWsPZAWZ+aeWdaxWJy/aM22QDuT99W7gpsz8\nzxx8zznlT/UzXgz4EXBmRIwa7DcZSseUvmTm/wFjBvo9bQqT+hBQS0RXRcS3IuKxWiLaqE6/LyIe\niogPtiz/k4j4QUT8oZYcL4+I5VrmZ61ivBO4s07bKCKuq2fx10XERnX6rhFxfa94PhUR59bH80XE\ncRFxb0Q8WN93/pZlD42IByLi/ojYZwbbGMB/A1/NzB9l5uOZ+XJmXp6Z+9Vl3hgRl0TElIh4OCJO\ni4hFW9YxMSI+HRE31e34RUSMbJm/U0TcGBFPRMQ/I2LrOn2RiPjfGue/I+KoiBjWx2f/CHDkjPZV\nZr6YmbcC7wcmA4e0vP/29f0fi4j/i4g16/SfAcsCv60lqc/U6RvU5R6LiL+1ltgiYvGIOLl+ro9G\nxDkRsSBwAbBUSyl3qSg1Cae2vHbHiLi1rveyiFilv5/hTLb9L8BtwCp1Xb+LiI+1LlPXu3N/1tfy\nmt0i4s+9pn02Is6qj0+NiBMi4uL6fb80Isa2LLtqRPwxIh6JiNsj4j0zeLttgMv7GdfIiDi+5Xvz\n3xExb8v8wyLiP3XefvV3N64l5iPr4yUj4vy6Px6JiCvq9J8DSwEX1H15cPSqOYiIJaL83h+o34Nf\nzSzuzHwZ+BmwEDCtKSwiNo6Ia2ocN0bEpi3z3hgRV9bP96KI+H5E/KTOe1Pdtg9FxL3ARf1Y34fr\nd+3JKMezXev0laLU1D0e5Td+ep0+vNfnt2j9DCfX9RwWEVHn7RvlmNd6vNyy18dwObDtzD6rRspM\n/zrwB0wEtqiP9wZeAj4EDKNUHd0LnADMB2wJPAksVJf/SX2+aZ3/beDKlnUn8AdKqXL++v9RYE9g\nOLBbfb4EsEBd14otr78O2LU+/h/g3LqOUcBvga/XeVsDDwKrAwsCp9f3flMf27tynbf8DD6TNwHv\nrNs0BrgC+J9en9m1lAPh4pQE85E6b33g8fr6eYClgZXrvHOAE2uMS9Z1HNDrs/9Y/Wzm7yOuI4FT\n+5j+FeDP9fE6wEPAW+s+/GCNd77e+7s+XxqYQjnwzFPjngKMqfN/B/yCUuoaAWxWp28OTJpefMBK\nwNN1fSOAzwB3AfPO7DPsY/v25tXfq/WAx4CV6vP39Wx/ff6Wug3zzmAfj6vfg+Et0+av6239Dt4M\n7FQfn1r37cb1u3ECcFmdNwr4N7BX3X/r1hjePJ33/yvwrl7fuZzOskcD/0f5Li4J/Bk4os7bHrif\ncoKzIPDzul3jWmI+sj4+Fvhu3R/z9uzLOm8SsPn04gEupPyuFquv3XQ6se7b8pkMBz4BPA+MrtPG\n1s9lK8r3bWvgYWCJOv9a4L963oNyTPhJa0zAyZTjxfwzWh+wcN1fK9bXvwFYtT7+JfDZ+pqRwMYt\nMbd+fqcDv677dwXKd/iDLdv6IrAP5bf2MeC+Xp/HZ4AzB/u43Q1/HQ9gbv3jtUn9zpZ5a9Qv+Ota\npk0B1qqPfwKc0TJvIWAqMLY+T+AdLfP3BK7t9f5XA3vXx6cCh9fHK9Yf9AJAUBLEG1tetyHwr/r4\nx8A3WuatxPST+sZ13sgBfEY7A3/t9Znt0fL8GOAH9fGJwLf6WMfrKAe3+Vum7QZc2vLZ3zuTOI6k\n76T+kZ79BnyfUgvROv8OXknG0/Z3ff5Z4Ge9lr+QcjLwBuBlYLE+3nNzZpzUv9R6MKMcPP9NTRwz\n+gz7eK+9KSc8jwFP1f33HSDq/PmAR3jl4H0c8L2ZfJbj6JXU6/QfAl+uj9eiJIgRLd/PU1uWXaR+\nPm8Adu/Zly3z/xf4wnTe/1+99sOMkvo9wJYtz7cD7qqPT2nd37xy0jquJeYj6+OjKQnqjX28x3ST\nOiVxvgQs0o/fyr4t++pF4BngPS3zvwCc3Os1F9fPbwVe+xs5g9cm9WX7ub6FaxzvotfvnZKsvw8s\n3Wv6tKROOfl5iXryWOcfCPyxZVtvb5m3cH3t6JZp/w+4aGafWxP/rH4fOh5sefwsQGb2ntbagea+\nngeZ+RTl4LpUX/Pr9Ht6vd89lNIilB/abvXxB4BzMvMZSgllAUrb8WMR8Rjw+zq9Z72t79P7PVpN\nqf+n2wZdqynPqNWZT1AOjKN7LdbaFvoMr3wmY4F/9rHa5SgHiQdatuFESsmrx319vK4/lqZ87j3v\nc0jPe9T3Gcur90nvuN7ba/lNKJ/PWOCRzHx0FmJ61b7OUhV7H6/sa5j+Z9iXazJz0Sxtta+ntIkf\nXdf9PHAmsEdEzEP5Dv1sFmIG+CklIQDsQenD8GLL/Nbv++OUkuBSlM9x416f4/uZ/vfsUUrprz/e\nwKu/062/md7f/Rl9h75RX3txlGahQ/v5/mOBh+v29seVmbkopQbmfMr3qcdywG69PqcN6nYsBUzJ\nzGdnsj2t06a7vsx8gvJdOBD4T0ScFxEr1dcdQvk9Xh8RN0dLs2KLJSkl8Ol99vDa7zC8+ns8inJi\nMdcxqXev1jbFhSg/5Ptb5mfL4/spP8JWy1JKcFDayEZHxFqUH+PpdfrDlJOJ1eqBfdHMXCRf6Z37\nQGscdZ3TcwfloDCj9s6v17jXzMyFKQf3mMHyre4D3jid6T3VkD3bsHBmrtayTPbxuhmqSWwH4E8t\n7/O1lvdYNDMXyMyfT+c97qOU1FuXXzAzv1HnLR4t/QkGEOur9nVthxzLK/t6ltWTzF/x6o6NPcl4\nAvBMZl49i+u+Eko7LX2fHLR+3xehlNbvp3xWF/f6HBfKzIOm81Y3UWqU+uMBXv27af3NPEDp7Pma\n+HrLzCcy81OZOY5S+/TZiNisZ/YM3v8+yu9y4X7G2/N+T1JKqh+O2q+jruvkPr5vx9ZtWSJe3bfi\nNduTtQjcj/WRmRdk5haUE6O7KCfSZOYDWa4MeAMl6Z8UEcv3equHKDWP0/vs+2MV4G8DWL4xTOrd\na9uI2KR23PkqpW1zeqWF84GVIuIDtUPK+4FVgfMAMvMl4CxK29/ilPb4nlLeD4FvRcSSABGxdERs\nVdd7JrB3lI5KCwBHTC/YekA4GPhS7XCzcETMU7fhpLrYKEo172MRsTTQ3xINlCrXD0XEhLrepSNi\n5cx8gHLS8s2W93xjy0F1QCJiRJSOZz+nlFz/u876IfCRiHhrFAtGxHbxSu/jBynVnD1OBXaIconf\nsCidsjaPiGVqzBcA34uIxep7btqyniVqYuvLmcB29XMYQSkZPU9pG54tEbEEpUr11p5pNYm/DHyT\nWS+l9/gZpWr26cy8pte8HSJiwyiXpB1FKZU+QOnvsVr9bo+of+tHxJun8x7nA6/Z9/Xzb/2bh7KP\nD4+I0RExhtK00dMh8UxK0nxz/e5/aXobFRE71O9cUGoYptY/eO33Ypr6e/4jcELtONb6PZihzJxM\naR7rietnwLsi4p0t37e3R8RSmflPSh+GIyJi3ojYhNLUMCPTXV9EvKFu8wLAC5QmvKn1s3hf/W1D\nKUlny2fRE/uLlOPR0RGxUE36n+KVz74/NqX8huY6JvXudToliT5C6Ry0+/QWzMwplI49h1CqwT8D\nbJ+ZD/da3xbAL2uS7/FZypn2NVGqxP8IvLmu9wJKR7pL6jKXzCjgzDyLUjW6D6WU9SDlAP2busiX\nKR3OHqd0FPv1jNbXa93XUjoafqu+/nJeOdPfi9IB6O+U6tezmEEzwHS8P8qgII9REskUYN3MvL++\n//XAfpQOUY9SPo+9W17/deCLtary0/WAvRPlmunJlJLPobzym9yT0jZ6O6Xk8sn6PrdTks3ddV2v\nqt7PzDsoNRzfodS07ADskJkvDHB7e2wYtac9pVPdZErHpFanUPqBDOSg25dTKJ0u+zo5OJXyXXkY\nWJPy+fRUxW9F2eYHKNWyX6e09/flHGDNiHh9r+nP9vrblPJ9/Bsl4d1E6Sj39fq+v6WcgFxBucLk\nqrqe5/t4zzdTfhtP1eW+3VMzQWnK+HLdl5/s47V71P//oPxeen/2M/ItYMeIWC0zJ1JOyL5E2Yf3\nUo4HPd+33eo2T6EcV34xnW0BYCbrG0b5Lj9Q17cR0FNz8lbguoh4mvL7PjD7vqTxo5QTgn9Rfss/\npXw/ZioiNqQ0X/2lP8s3TU+HF3WRKJeaTMrML3Y6Fiki9gL2z8xNZrrwjNezIOUEZvXM/FfL9FMp\nHdSOnK1AX1nfR4EVMvPTg7G+us41gL9QrnZ4ebDW2ylRLp27MTO/2ulYBioifgOckJkXdTqWThjS\ngwhIGtpqFetHge8NwuoOBK5qTejtkJmDESsR8S5KjdIoSme433RrQo+I9Skl7nsol6dtT6mp6DqZ\nuVOnY+gkq98lzZLat2IypVr49JksPrN1TaJ07hq00vMccCClOeBO4Ln6vFstRWlKeJJSbb9fZt7U\n2ZA0K6x+lySpISypS5LUEF3Xpj569OgcN25cp8OQJGmOuOGGGx7OzDEzX7ILk/q4ceO4/vrrZ76g\nJEkNEBEzGq3zVax+lySpIUzqkiQ1hEldkqSG6Lo2dUlS87z44otMmjSJ5557rtOhdMzIkSNZZpll\nGDFixCyvw6QuSeq4SZMmMWrUKMaNG0e5983cJTOZMmUKkyZNYvnle9+4rv+sfpckddxzzz3HEkss\nMVcmdICIYIkllpjtmgqTuiRpSJhbE3qPwdh+k7okSQ1hUpckaTrGjRvHww8/PNvLzCkmdUmSGsKk\nLklqlIkTJ7Lyyiuz7777svrqq7P77rvzxz/+kY033pgVV1yRa6+9lkceeYSdd96ZNddckw022ICb\nbip3mp0yZQpbbrkla6+9NgcccACtdzI99dRTWX/99VlrrbU44IADmDp1aqc2cbpM6pKkxrnrrrv4\nxCc+wU033cTtt9/O6aefzpVXXslxxx3H0UcfzRFHHMHaa6/NTTfdxNFHH81ee+0FwJe//GU22WQT\n/vrXv7Ljjjty7733AnDbbbfxi1/8gquuuoobb7yRYcOGcdppp3VyE/vkdeqSpMZZfvnlWWONNQBY\nbbXVmDBhAhHBGmuswcSJE7nnnnv41a9+BcA73vEOpkyZwuOPP84VV1zBr3/9awC22247FltsMQAu\nvvhibrjhBtZbbz0Ann32WZZccskObNmMmdQlSY0z33zzTXs8zzzzTHs+zzzz8NJLLzF8+GvTX88l\nZX1dWpaZfPCDH+TrX/96myIeHFa/S5LmOptuuum06vPLLruM0aNHs/DCC79q+gUXXMCjjz4KwIQJ\nEzjrrLN46KGHAHjkkUe4555+3xF1jrGkLkma6xx55JF86EMfYs0112SBBRbgpz/9KQBHHHEEu+22\nG+ussw6bbbYZyy67LACrrroqRx11FFtuuSUvv/wyI0aM4IQTTmC55Zbr5Ga8RrT27BvUFUf8GNge\neCgzV+9jfgDfBrYFngH2zsy/zGy948ePz+uvv36ww5UkddBtt93GKqus0ukwOq6vzyEibsjM8f15\nfTur338CbD2D+dsAK9a//YHvtzEWSZIar21JPTOvAB6ZwSI7AadkcQ2waES8oV3xSJLUdJ1sU18a\nuK/l+aQ67YHeC0bE/pTS/LT2DQ2Oe7+yRlvWu+zhN7dlvZKk6etk7/e+bkfTZwN/Zp6UmeMzc/yY\nMWPaHJYkSd2pk0l9EjC25fkywP0dikWSpK7XyaR+LrBXFBsAj2fma6reJUlS/7StTT0ifg5sDoyO\niEnAEcAIgMz8AXA+5XK2uyiXtH1odt5v3UNPmZ2XT9cNx+7VlvVKkqZvsI/pg30s33vvvdl+++3Z\nZZddBnW9s6ttST0zd5vJ/AQObNf7S5I0t3GYWEmSqlNOOYU111yTt7zlLey5557cc889TJgwgTXX\nXJMJEyZMu2sbwBVXXMFGG23ECiuswFlnnTVt+rHHHst6663HmmuuyRFHHAGU28Gussoq7Lfffqy2\n2mpsueWWPPvss4Mev0ldkiTg1ltv5Wtf+xqXXHIJf/vb3/j2t7/NQQcdxF577cVNN93E7rvvzsc/\n/vFpyz/wwANceeWVnHfeeXzuc58D4KKLLuLOO+/k2muv5cYbb+SGG27giiuuAODOO+/kwAMP5NZb\nb2XRRReddpe4weTY712gXf0FAM4e1bZVS1JXueSSS9hll10YPXo0AIsvvjhXX331tFux7rnnnnzm\nM5+ZtvzOO+/MPPPMw6qrrsqDDz4IlKR+0UUXsfbaawPw1FNPceedd7Lsssuy/PLLs9ZaawGw7rrr\nMnHixEHfBpO6JEmU26v2ddvVVq3zW2/v2nMflczksMMO44ADDnjV6yZOnPiq5YcNG2b1uyRJ7TJh\nwgTOPPNMpkyZApTbq2600UacccYZAJx22mlssskmM1zHVlttxY9//GOeeuopAP79739Pu13rnGBJ\nXZI05HTicuLVVluNL3zhC2y22WYMGzaMtddem+OPP5599tmHY489ljFjxnDyySfPcB1bbrklt912\nGxtuuCEACy20EKeeeirDhg2bE5vQvluvtsv0br3a5OvU29umfmxb1uvY75IGwluvFkP51quSJGkO\nMqlLktQQtqnPhLcmlSR1C0vqkiQ1hEldkqSGMKlLktQQtqlLkoacwe7P1J9+TMOGDWONNdYgMxk2\nbBjf/e532Wijjaa7/MSJE9l+++255ZZbBjPU2WJSlyQJmH/++bnxxhsBuPDCCznssMO4/PLL2/Je\nU6dObcuANFa/S5LUyxNPPMFiiy0GlJuyTJgwgXXWWYc11liD3/zmN69Z/u6772bttdfmuuuuY+rU\nqRx66KHTbr964oknAnDZZZfx9re/nQ984AOssUZ7rqyypC5JEvDss8+y1lpr8dxzz/HAAw9wySWX\nADBy5EjOPvtsFl54YR5++GE22GADdtxxx2mvu+OOO9h11105+eSTWWuttTjppJNYZJFFuO6663j+\n+efZeOON2XLLLQG49tprueWWW1h++eXbsg0mdUmSeHX1+9VXX81ee+3FLbfcQmby+c9/niuuuIJ5\n5pmHf//739NutTp58mR22mknfvWrX7HaaqsB5farN910E2eddRYAjz/+OHfeeSfzzjsv66+/ftsS\nOpjUJUl6jQ033JCHH36YyZMnc/755zN58mRuuOEGRowYwbhx43juuecAWGSRRRg7dixXXXXVtKSe\nmXznO99hq622etU6L7vsMhZccMG2xm2buiRJvdx+++1MnTqVJZZYgscff5wll1ySESNGcOmll3LP\nPfdMW27eeeflnHPO4ZRTTuH0008Hyu1Xv//97/Piiy8C8I9//IOnn356jsRtSV2SNOR0YijtnjZ1\nKKXtn/70pwwbNozdd9+dHXbYgfHjx7PWWmux8sorv+p1Cy64IOeddx7vfOc7WXDBBdl3332ZOHEi\n66yzDpnJmDFjOOecc+bINpjUJUmiXGbWl9GjR3P11Vf3Oa/nGvVFF12U6667btr0o48+mqOPPvpV\ny26++eZsvvnmgxPsdFj9LklSQ5jUJUlqCJO6JGlIyMxOh9BRg7H9JnVJUseNHDmSKVOmzLWJPTOZ\nMmUKI0eOnK312FFOktRxyyyzDJMmTWLy5MmdDqVjRo4cyTLLLDNb6zCpS5I6bsSIEW0daW1uYfW7\nJEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqS\nJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS\n1BDDOx2A1E73fmWNtqx32cNvbst6JWl2WFKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklS\nQ5jUJUlqCJO6JEkN4eAzkoYkBw6SBs6SuiRJDWFSlySpIUzqkiQ1hG3qkqRBZ5+IzrCkLklSQ5jU\nJUlqCKvfpS7VrupNsIpT6laW1CVJagiTuiRJDWFSlySpIUzqkiQ1hEldkqSGMKlLktQQJnVJkhrC\npC5JUkO0NalHxNYRcUdE3BURn+tj/rIRcWlE/DUiboqIbdsZjyRJTda2pB4Rw4ATgG2AVYHdImLV\nXot9ETgzM9cGdgW+1654JElqunaW1NcH7srMuzPzBeAMYKdeyySwcH28CHB/G+ORJKnR2pnUlwbu\na3k+qU5rdSSwR0RMAs4HPtbXiiJi/4i4PiKunzx5cjtilSSp67UzqUcf07LX892An2TmMsC2wM8i\n4jUxZeZJmTk+M8ePGTOmDaFKktT92pnUJwFjW54vw2ur1z8MnAmQmVcDI4HRbYxJkqTGauetV68D\nVoyI5YF/UzrCfaDXMvcCE4CfRMQqlKRu/bqkxmvXrXO9be7crW0l9cx8CTgIuBC4jdLL/daI+EpE\n7FgXOwTYLyL+Bvwc2Dsze1fRS5KkfmhnSZ3MPJ/SAa512uEtj/8ObNzOGCRJmls4opwkSQ1hUpck\nqSFM6pIkNYRJXZKkhjCpS5LUECZ1SZIawqQuSVJDmNQlSWoIk7okSQ1hUpckqSFM6pIkNYRJXZKk\nhjCpS5LUECZ1SZIawqQuSVJDmNQlSWoIk7okSQ1hUpckqSFM6pIkNYRJXZKkhjCpS5LUECZ1SZIa\nwqQuSVJDmNQlSWoIk7okSQ1hUpckqSFM6pIkNcTwTgcgrXvoKW1b99mj2rbqfmvX9g2FbZM0tFhS\nlySpIUzqkiQ1hEldkqSGMKlLktQQJnVJkhrCpC5JUkOY1CVJagiTuiRJDWFSlySpIUzqkiQ1hEld\nkqSGMKlLktQQJnVJkhrCpC5JUkOY1CVJagiTuiRJDTG80wFI6m7rHnpKW9Z79qi2rFZqNEvqkiQ1\nhEldkqSGMKlLktQQJnVJkhrCpC5JUkOY1CVJagiTuiRJDWFSlySpIUzqkiQ1hEldkqSGMKlLktQQ\njv0uSTPg2PbqJpbUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jU\nJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqiLYm9YjYOiLu\niIi7IuJz01nmfRHx94i4NSJOb2c8kiQ12fB2rTgihgEnAO8EJgHXRcS5mfn3lmVWBA4DNs7MRyNi\nyXbFI0lS0820pB4RB0XEYrOw7vWBuzLz7sx8ATgD2KnXMvsBJ2TmowCZ+dAsvI8kSaJ/1e+vp5Sy\nz6zV6dHPdS8N3NfyfFKd1molYKWIuCoiromIrftaUUTsHxHXR8T1kydP7ufbS5I0d5lpUs/MLwIr\nAv8L7A3cGRFHR8QbZ/LSvpJ/9no+vK57c2A34EcRsWgfMZyUmeMzc/yYMWNmFrIkSXOlfnWUy8wE\n/lP/XgIWA86KiGNm8LJJwNiW58sA9/exzG8y88XM/BdwByXJS5KkAepPm/rHI+IG4BjgKmCNzPx/\nwLrAe2bw0uuAFSNi+YiYF9gVOLfXMucAb6/vM5pSHX/3gLdCkiT1q/f7aODdmXlP68TMfDkitp/e\nizLzpYg4CLgQGAb8ODNvjYivANdn5rl13pYR8XdgKnBoZk6Z1Y2RJGlu1p+kfj7wSM+TiBgFrJqZ\nf87M22b0wsw8v76+ddrhLY8TOLj+SZKk2dCfNvXvA0+1PH+6TpMkSUNIf5J61BI1UKrdaeOgNZIk\nadb0JznfHREf55XS+UexM5skdb11Dz2lbes+e1TbVq0Z6E9J/SPARsC/KZegvRXYv51BSZKkgZtp\nSb0O3brrHIhFkiTNhpkm9YgYCXwYWA0Y2TM9M/dpY1ySJGmA+lP9/jPK+O9bAZdTRoZ7sp1BSZKk\ngetPUn9TZn4JeDozfwpsB6zR3rAkSdJA9Sepv1j/PxYRqwOLAOPaFpEkSZol/bmk7aR6P/UvUsZu\nXwj4UlujkiRJAzbDpB4R8wBPZOajwBXACnMkKkmSNGAzrH6vo8cdNIdikSRJs6E/bep/iIhPR8TY\niFi856/tkUmSpAHpT5t6z/XoB7ZMS6yKlyRpSOnPiHLLz4lAJEnS7OnPiHJ79TU9M9t3JwBJkjRg\n/al+X6/l8UhgAvAXwKQuSdIQ0p/q94+1Po+IRShDx0qSpCGkPyX13p4BVhzsQCRJ6hb3fqU9o6Uv\ne/jNs/X6/rSp/5bS2x3KJXCrAmfO1rtKkqRB15+S+nEtj18C7snMSW2KR5IkzaL+JPV7gQcy8zmA\niJg/IsZl5sS2RiZJkgakPyPK/RJ4ueX51DpNkiQNIf1J6sMz84WeJ/XxvO0LSZIkzYr+JPXJEbFj\nz5OI2Al4uH0hSZKkWdGfNvWPAKdFxHfr80lAn6PMSZKkzunP4DP/BDaIiIWAyMwn2x+WJEkaqJlW\nv0fE0RGxaGY+lZlPRsRiEXFZEatIAAAgAElEQVTUnAhOkiT1X3/a1LfJzMd6nmTmo8C27QtJkiTN\niv4k9WERMV/Pk4iYH5hvBstLkqQO6E9HuVOBiyPiZMpwsfvgHdokSRpy+tNR7piIuAnYAgjgq5l5\nYdsjkyRJA9Kvu7Rl5u+B3wNExMYRcUJmHtjWyCRJ0oD0K6lHxFrAbsD7gX8Bv25nUJIkaeCmm9Qj\nYiVgV0oynwL8gnKd+tvnUGySJGkAZlRSvx34E7BDZt4FEBGfmiNRSZKkAZvRJW3vAf4DXBoRP4yI\nCZSOcpIkaQiablLPzLMz8/3AysBlwKeA10XE9yNiyzkUnyRJ6qeZDj6TmU9n5mmZuT2wDHAj8Lm2\nRyZJkgakPyPKTZOZj2TmiZn5jnYFJEmSZs2AkrokSRq6TOqSJDWESV2SpIaY6YhyEfEk5UYurR4H\nrgcOycy72xGYJEkamP4ME/vfwP3A6ZTr1HcFXg/cAfwY2LxdwUmSpP7rT/X71rXH+5OZ+URmngRs\nm5m/ABZrc3ySJKmf+pPUX46I90XEPPXvfS3zelfLS5KkDulPUt8d2BN4qP7tCewREfMDB7UxNkmS\nNAAzbVOvHeF2mM7sKwc3HEmSNKtmWlKPiGUi4uyIeCgiHoyIX0XEMnMiOEmS1H/9qX4/GTgXWApY\nGvhtnSZJkoaQ/iT1MZl5cma+VP9+Aoxpc1ySJGmA+pPUH46IPSJiWP3bA5jS7sAkSdLA9Cep7wO8\nD/gP8ACwC/ChdgYlSZIGrj/3U783M3fMzDGZuWRm7gy8ew7EJkmSBmBWb+hy8KBGIUmSZtusJvUY\n1CgkSdJsm9Wk7vCwkiQNMdMdUW46t1yFUkqfv20RSZKkWTLdpJ6Zo+ZkIJIkafbMavW7JEkaYkzq\nkiQ1hEldkqSGMKlLktQQJnVJkhrCpC5JUkOY1CVJagiTuiRJDWFSlySpIUzqkiQ1hEldkqSGMKlL\nktQQJnVJkhqirUk9IraOiDsi4q6I+NwMltslIjIixrczHkmSmqxtST0ihgEnANsAqwK7RcSqfSw3\nCvg48Od2xSJJ0tygnSX19YG7MvPuzHwBOAPYqY/lvgocAzzXxlgkSWq8dib1pYH7Wp5PqtOmiYi1\ngbGZed6MVhQR+0fE9RFx/eTJkwc/UkmSGqCdST36mJbTZkbMA3wLOGRmK8rMkzJzfGaOHzNmzCCG\nKElSc7QzqU8CxrY8Xwa4v+X5KGB14LKImAhsAJxrZzlJkmZNO5P6dcCKEbF8RMwL7Aqc2zMzMx/P\nzNGZOS4zxwHXADtm5vVtjEmSpMZqW1LPzJeAg4ALgduAMzPz1oj4SkTs2K73lSRpbjW8nSvPzPOB\n83tNO3w6y27ezlgkSWo6R5STJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6\nJEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqS\nJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqiOGdDkCSpHZY99BT2rbus0e1bdWzxZK6JEkN\nYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWE\nSV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAm\ndUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jU\nJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKX\nJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkh2prUI2LriLgj\nIu6KiM/1Mf/giPh7RNwUERdHxHLtjEeSpCZrW1KPiGHACcA2wKrAbhGxaq/F/gqMz8w1gbOAY9oV\njyRJTdfOkvr6wF2ZeXdmvgCcAezUukBmXpqZz9Sn1wDLtDEeSZIarZ1JfWngvpbnk+q06fkwcEFf\nMyJi/4i4PiKunzx58iCGKElSc7QzqUcf07LPBSP2AMYDx/Y1PzNPyszxmTl+zJgxgxiiJEnNMbyN\n654EjG15vgxwf++FImIL4AvAZpn5fBvjkSSp0dpZUr8OWDEilo+IeYFdgXNbF4iItYETgR0z86E2\nxiJJUuO1Laln5kvAQcCFwG3AmZl5a0R8JSJ2rIsdCywE/DIiboyIc6ezOkmSNBPtrH4nM88Hzu81\n7fCWx1u08/0lSZqbOKKcJEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlq\nCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkh\nTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYw\nqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKk\nLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6\nJEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqS\nJDWESV2SpIYwqUuS1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkhTOqSJDWESV2SpIYwqUuS\n1BAmdUmSGsKkLklSQ5jUJUlqCJO6JEkNYVKXJKkh2prUI2LriLgjIu6KiM/1MX++iPhFnf/niBjX\nzngkSWqytiX1iBgGnABsA6wK7BYRq/Za7MPAo5n5JuBbwH+1Kx5JkpqunSX19YG7MvPuzHwBOAPY\nqdcyOwE/rY/PAiZERLQxJkmSGisysz0rjtgF2Doz963P9wTempkHtSxzS11mUn3+z7rMw73WtT+w\nf336ZuCOtgTdt9HAwzNdqnu5fd2rydsGbl+3c/sGz3KZOaY/Cw5vYxB9lbh7n0H0Zxky8yTgpMEI\naqAi4vrMHN+J954T3L7u1eRtA7ev27l9ndHO6vdJwNiW58sA909vmYgYDiwCPNLGmCRJaqx2JvXr\ngBUjYvmImBfYFTi31zLnAh+sj3cBLsl2tQdIktRwbat+z8yXIuIg4EJgGPDjzLw1Ir4CXJ+Z5wL/\nC/wsIu6ilNB3bVc8s6Ej1f5zkNvXvZq8beD2dTu3rwPa1lFOkiTNWY4oJ0lSQ5jUJUlqCJO6JEkN\nYVLXNI7mJ0ndzaQ+iyJiXEQs1ek4BktERM/lhBGxVUSs3OmY5pSmn8w0ffvmJtPbl+7joSEi5mt5\nPKwTMZjUByiKhYFjgDV7pnU2qtnXktC3AD4BPNDZiOaMXiczw3r2ZUQ04rfRa/s+HBEHdjqmdmvZ\nh2+KiKU7Hc9gatmXu0fE+yPirT3Tu+E4FBFrRMTrOh1HO9S88I6IWCEiPgHs0Yl90ogD15yUxRPA\nRcBnI2J0UwbMiYidKXfOOzMzH+90PO0WEcsCC9bHnwC+B3wrIhbKzJebkNhbksCnKfv2stb53ZAI\nBqomuB2B0yjjc3e91v1Uf6dfBCYAH4qID8PQTewtJ1mrAEcAx0dEv8Yx7zLPUO5I+gvgAOBPncgN\nXX/QmpMiYrmI2CAihmXmj4AbgdfVeV33WfZxAHgQWBYYHxELdSCkOaKltuUUYJ+I2JYy8NFvgfmB\n37ck9o5UoQ2miFgS2BTYGJgcEe+JiO9FxPChmghmR0SMB74C7JmZf4uI0RGxYqfjmlW9aluWBpYH\nds7M/SknaetHxIfglZO4oaR+x3YCfgDcSzmR/nZEvKGzkQ2Ont9PZr5EOYa8BFwLjIyI+ed0PF2X\niDqlVksfB+wJ/CoilgfeAOwLkJkvdzC8Aet1oNgmItYH/gPsDqwG7B4RC3YyxnaqtS2HAdtR9unx\nmXleZh4A3AScHxGjMnNqJ+OcFX0k6ScoJdYLgW9Tbou8DvAdGJqJYKB6bfMw4K/A2hHxGeBM4HsR\nsXVHgpsNvX6nB1NuVX0osEld5PfApcAWUe6EOeRExAhgN+ALmXkwcAhwD/Bf3V5i77V/3g+sBWxD\n2b6PAuvWeSvWz6HtTOr9UNutDgb+JzMPBG6mJPNFgPdExAadjG9WtHwRPw58AdgQuIBylvkFylj8\n+0XEAh0Lsg1af4TAn4EDgTHAhrX0TmZ+FJgInNVtpdheB5m311LrS8DWwNnAFzPzs5SSLHPqQNNu\ntTS4Yf0t/gu4C/gM5eD6aUrym28GqxiSWk+8gY2A9wBHAZ+OiA0z8zFKU+CvgT90LNAZmwdYjJLw\noOyb64EVgS9HxCKdCmx2teyfQ4FPArfWffINYDKwa0R8j/LbW3hOBeXfDP6AccCvgE/3mr4E5Uf2\nW+DjnY5zANvTMzRwUO5Nf0F9fhTlBjvD6/MN6vNFOx1zmz6HA4Dv1cdrA5cABwELtyzz+k7HORvb\ndwjwJ+DHlHssbNAy79PA34A1Oh3nIG/zp4FbgXXq8wXq/3Xr9M06HeMAtiVaHi8HnAX8oWXaQcDf\ngU17L9/pv5ZjzJuBcfXxRpQTq/fW5xsCxwM/Ad7a6Zhnc3tXAi6tjxeknEB/pD5/N+UEevU5Fk+n\nP5Ch/lcP+D8GrgFWbpk+T/2/InAVsHinYx3gdg2nnDmeSCmZnwfMX+ftCowA5ut0nG3a9j1qUntj\ny7Tx1M6PwKhOxzib27c1cH59/C3gL8AJlI5VIyg3ophjB5k5sL1jWh4fTLlD5Fvr8w0ofV927HSc\ns7htPduxdf2Nfqpl3qGUEu/IoZLUWxL6lsDtlLblQyml9O0opfT/pbStr0FpZ39/p+OelW1seb4Y\n8H+Uwt9J9UTlDuCIvpZve3yd/oCG2l/Ll/KNwOKUKrsxwNGU9siVei33NuAWWkp4Q/2P0mnqovr4\nXOD+lnl7A1e2Hiib9EepCjwO2KU+n6/lBG0d4DfAYp2Oc4Db1PsgsyalM9V+lCrZFep+voBSYhoS\nCWCQtn1c/V2+q2XaITVpbEjpyPqq32y3/FFKff8AjqnPt6OchH+yZZkh912lnCD/sn7v1qacUH4G\nGAssDWwOvKl+F28CVuh0zAPYttYalLcAK9bHbwL+C1i1Pn8PcGQnvnO2qfeSmVl7Q59Dqc47A3iO\n8sV8nNKW9ease45yy9idsnS8GpJaLinpaR++GfhX7ez3aeCaiDg3Io4EPgb8v8yc3JFgB1nvNvEs\nHRofBjaNiEUz8/ksvdzfRekouEtmPtqJWGdFrzb0dSJicWBSZv4LWBk4OjPvppTW7wD+2fLd7Wq1\nk9W/KW2Xm0TE9gCZ+U3gbuCbwDOZ+Y86vWu2u+7Xp4EtgM0i4qjM/B3luLR+RHy0LvpYx4LsQ0SM\nBPainFD9JzP/SunctyywP6VJ5DJgIUoJfs/6/ewKLb+1T1NqwY6vx81nMvOzmfn3KLccPxw4qxPf\nOZN6L7Vj0THAu4D7gfUopZ2ngB8BUyi9awHIzFsz858dCLVf6qVZPV+snkEfngESOKAe8N5PaVO+\nDdgtM2+e85EOvl4Jb6OIWK/26P8d5dK17SNibES8l3JyMzwzX+xgyAPWsn0fA/6bcqD8TkSMopy8\n/CIiPg/sSOno+WDHgh0ELSeoK1F6tW9JKSH9B3h7lAFZxgN3Aodk5pMdC3YAWk8+I2IHyraMyMx7\nKceibSPisMy8gFK9ezYMrROViHhLZj5H2R83UBLe/Jl5LXAqsCTQc5XQncC+mfm3zkQ76yLifcCW\nmfkOyknl+4CPRMSqEfF6YDNgj8y8pSMBdro6Yyj9AQtQqi5Xo7Q/Xk9JhGdR2ukWoYvamSkltf0p\n7ecrUUpqewOLUtrTLwZ26HScc+BzOIjS0/2Y+n8kpQR0Qv0MLgHW7HScs7F9b6NcrzwcOBk4o2Xe\nh4BjqdWCTfgDtgdOb9l376KcaO9PqVm7A9i203EOYHsWBpaoj5ek9Ou4hNJMNm+dvgfwLOVEpeMx\n94q/pynyBl7pyzGW0l7+fV7pq7NI/T9Pp2Oexe3r+b85pXn2IEqT1rqUSyhPonQOnLeT8fYEOdeL\niDWAvTLz0Pr8GODmzPxZvT50Z+CzmXl1J+MciIhYnTLc62hK2/FCwEcolzhNptRETM3M73YsyDaL\niO2AzwPvpAx/ewjwJPCWzHwiyvj9T2cXjaDXqwZiAUq75caU7dqJ0hz0fERsmplXRMQ82WXjKExP\nHbDkj5TOnI8Cb6WcuPwgM8+ry6yQXVKlGxHDKW3lS1ASwuqZuV2UEQ63Br6RmZdHxLsphY2fZ+Zd\nnYv4tSJivsx8vj6+mtL8896IGAt8DXiR0r+Dbvse9vqtrUhp1hmWmS9ExE+Ab2bmzRFxPKUPxGcy\nc0rnImbuTeq9rlemtkVeCfxXZv40Io6mNE/cDOxDaWf+R2ei7b8+tmsxyuVqj1HagJ6kdFb5OqWj\nyjDKWedz2YAvQx/b33PTna0pvWy3iojfUzrFvTm7qP28t4jYj1Ib8y1KE9GLmdlzP4IDKCcye2fm\nU52LcnBFGdr31MzctD5fgjL06DqU5oWzOhnfQPR8VyOi55K1sZSCxUV1/scpNYZPU0qDW2XmxE7F\n25daGNqA0vH2njrtBkrfjffVbRuVnaqKHiR1X2xL6dE/hVL79VVK34FfUmqL9h4K+2eubVNvOfua\nt7ZdPUJpj+y5O9lplNLtzsAJ3ZDQq2EwrQRATVo/o1TNHgS8KTPvzsz3U9qCNszMZ5uQ0OFV+3X5\niBibmfdn5v2UMZnPqIv9lnLd8mIdCnO21Xa9dYHvZOYkymAXt0bE56PctGV/4MvdntBb2tAXBMjS\nxnxPRPyw1kBMoTSNXU8ZVW1M786RQ1Gvk8+plE59lwGrRMRaAJl5PCVx/BDYbigkDHjN3ceWo5ww\nT6glcygDV+0SET/NzHsakNC3pfRm34HSjLlclr4Dx1CuKtkIOHDI7J+GHMv7LSJWoAzj9zSlvfzN\nlGvQrwUmUQ78n83MG6KMtpWZ+VLvEuBQFBGjKQe3dTLzkYiYNzNfqPPeSvliPkEZcOaGDobaVhHx\nWeADlNqJSzLzy1FGfFqe0knwLZSOLF3TaaxXNeC8wHcpJ2VvysyHa0/wcZRqzvuBX2bmrZ2KdzC0\nlGS3o2zrJEqHq5cpQ3CuTUl4n6eckO9BuY67a+4wGBEfAd5B+b4uS7lRyz8pfSPWAx7JzD91LsJX\nRLla5pHMfDzKfQNeqtO3ocR/KaV3/hso++LizPxjxwKeRX3U9m0LLEP53r2XMubB8xGxembe0nqc\nHQqGdzqAOSkiVqWcWf2Ocpna9pT2nr9Q7qxzMGWIya9ExPtbSzlDPaED1IP7x4D/izKE5KO1FuLF\nzPxzRDxHuVPX2yPilp52sG7XK+GNpJysvZPSh+CKiHiGMnrVHpQD5cFdnNB7BvD4FKXj5qkRsUOW\nSxAnU0qtjVAT+haUpqIPUBLdKvX/Fyg1T8vVefNSTmq6ps02yljhH6XcnOUl4O7al+fTlHExtqb0\npB4q3gj8JSKWz8zHepJZZl4Q5YZW7wa2opRcd6/9OYZ8YahVr9/awZSrZH5DqUl5LDM3rPM+Brwl\nIg4casfRuSapRxlf+AfA1zLz5DrtvynXUI6knIHtT+lUtgklIXRd1WVm/jYiXgKuj4jxNbH3nEkO\np/QROGeofRFnVa8f4X6U9r3FKD1Q746IjSl9JRbJzC9SRrPqKi3b91FKEtgxM5+OiL0pJytnRcR7\nh1JpYXbVJDGCcsnaXpR+IFBKsR+lnJQfm5lTI+JtlH4FH+6Gk7WW5oHlKP0A7o6I+Sh9Im6Pcg30\ncsCXMvO+jgXaS2b+MSJ2A25oObbMB7yQmb+LiPsp+2WhzLyuvqZrEjq86re2PWUUvM9STpZ/CSwS\n5aY5wylXEX1wSB5HcwhcMjAn/iiJ+2fAgj3P6/9lKdWVW1P6GIwB3tbpeAdhe7ehHAAXq88Polwb\nukynY2vT9m5GuQvZ5yi1MZ+gtH1BqXa/re7brhpVrGX7VqUMRTm2Pu8ZBW9BSv+PMzsd4yBtZ8+9\nB3q2b4G63y6kjtpI6Q9xIvC6+nw9YNlOxz6T7XrN946SGH4DLNUybXdgo07HO5Nt6Tm2LN4ybVPK\nJaILdTq+WdymJVqOlaPqb+qOlvmrUJovf0Fp+hqywyzPNW3qtRf4VcChWUZmoqcEGxGHAS9l5rG9\nXtNVVUe91bau/6IMVrEfZWCZGzsaVBtEGTzmOErv9muijA63KeUOXb/JzH+1tgF2gz7a9ZaidIbb\nh3IznpezlFJfT7miYVRm/qcz0c6+KFefPJGl/8rbKSdpF2fmn2ot2x8po3T9A/gf4PAso5UNeb1q\nk3ah9HK/gTIA1DspTYC/oSSOg4EP5BAe0AqmHVtOyMwVImI1ynX1H8nMszsc2oDVNvMjKXdmvCMz\nv1S36VhKL/6PtSwblBPOIXtL5rmm93uWXuDfptwqtecWgD075mVK20nv13RtQgfIMvrUYZSEt2tT\nEnofvZvPp1x7fxhAPbBcCqwObBPlSoAh+yPsrVcSWLROfoJy0P9olj4SUyNiL0onsRe7PKEvSBkb\n/NCI2Jxyn/dRwIm1ieEFymh5X6IkvxO7JaHDa0b9+yTwPGWgkiUo39OgnKjsBew31BM6TDu2HBgR\nz1IGATogM8/uhisPWkXE1pTf0Nco/RiWr4W9WyknWAvUZlqg7MuhnNBhLuv9XnsIf5Jyo5azMvPi\niNiIUtWyT2Ze2tEA2yQiFsjMZzodx2DolfDWp1zCd139fwNwbWbuU+dvC9yQXdDO2iNaBoqJiE9S\nBlm5nNKreBLldqoXUNouN6NcG3tTh8IdFLU3/w6UDlYrUUqAv6+dAj9CGQ72t5Q29sWySy4v7ePk\n7HjKQDl7U0rjE3r2d5RhfV/KzGc7F/HARcQ7KLdn/nW31WzW2qGHgffUE5L1KSeNZ1NqUT5GuQvn\nUcCdmfn5jgU7AHNVUgeIiNdRxjo/kJIMVgG+kpm/6WhgGpAol6i9i5Lc/kW5ouE8yjCw/8hyHX7X\niohNgH0pJ5wrUQa5+CGlo+M2lJ7vf8jMOzsW5CBoSWrzUqqiD6GcvHw4M1+s1byfAU7PzB92MtaB\n6JXQt6U0HxxJGSQHYJvMzIjYH/i/7P5rubsqofeoJ45HUU60jqP0W/lfSse4OzNzjyhXTT2aXXKp\n5FzT+71HLbUdHxFn1kkjM3Nit34p5xY9+6dW7y1HKdm9jdJssjnlhiU312mXRRlO9D/dtk/r9m0I\nXEEZ0OIPEfF3ypCo+wLnZeZpnYxxsNR9+nJELENpQvhdlMsudwIOjohv5iuXSz3U2WgHpiWhv4fS\nafNmys0/NqT0B8iI+ADwccpogF2t235nPep3bipl7PbPZ+Y3ACJiAnBuRCySmX/vaJADNNeV1NV9\nImJU1rtt1Y5hz1HOqN+Zmf+unSCPA/6amd/tthO0vuKNiJMoJy7jsgx08TrKGOHrUy6zeaKbtnF6\naknpm5RbGN9FuSb9TZRS+8OUW8d2TQfHVlHuFncsZejp30fEG4EDKNs3D+WqjN27vZTeBBHxTkqv\n9rdmuQb/Q5TOxVtll9zpr4dJXUNa7fn8QUoP7xHAuzJzmyiDdAB8uyb2z1HGFjgcuufGEb2qaTek\nXBL0h/r8B5Sxv9fJzCdrn5DnM/OJzkU8eKLcPvWrwFFZbopxEqUT2WGUGpedgGOye27O0vuKhU0p\nl1i+SOkA91A9AV0YeD1wb7dU6c4NalPPscD3KH1ZPtqNJ1wmdQ1ZtRS3AfBrSpvkc5QE92CUYW93\nqH/nAHtS2inv6FS8A9FHAvgkZQCkSZT28k9k5h1R7v60O+Wa+64bDKkvtYlhDOW65uUonf3+Xudd\nDvyeMq724llGyhvyep2cvYVyRc2tlFs570rpePXNzHy4c1FqZqIMOvNrYO3s0mGW55pL2tRd6o/r\naOAmSnvkdyiXde0GkJl/plzi9EXKoDpbdUtCr6b1Z6knL+/OzI0pQxavDnw1IlbKzI9TOu68vjNh\nDp6ey53qZUEPUS7jegB4W5S7r0HpDDg8M6d2Q0Jv3ab6/BOUUSqPAS6iXK52AeXqjC/VHtcaorLc\nvnfRbk3oYEldQ1BtN/855d7E17VMH0+5vOlbmfmdKAN53JqZt3Uo1FlS2+/2Af5GuQHPlZSS6zsp\npfXtKNfejwb27Lbt60tLR8ctKOODP0UZ4XERSh+BFymfw8cp+/13HQt2ACJiyVqtHpQbBX2Pcke1\nRyPiCMo90Pen3P1xO+D4bjhZUfeypK6h6HnKQf65iJg/Io6s1bKfoVRPfyEiTqR0sOqKtvMeUQa7\n+Bqlo9+ClAFHVs8yxvdqwLm1P8BvKaXYKZ2KdTDVhP4Oyj67m1KCvYayr4+mDMSyGvDJ2iN5yA9i\nUvs4XBoR76sl9Qfr3xiAzPwyZTs/npnXUDr9mdDVVnPdJW3qCo9Rxvo+jnKg/yOlVHcb5c56p1Eu\nD/p6DpF7GPdHrXo9H9gpy413xlK2cVlKif06YL96XeyalLbmrrqUaybGA6dk5vcBIuJuyr7chNK+\n/l5gXE/pt3Nh9k9mTo6IwyknmVMz81cR8QSwXkQ8VrfhCsod5MguG1hG3cmkriGnlupOpN7AhDJ+\n+/Mw7U5sf6ltX10lyz3udwCOiYjLM/O+iHiRWrKjjBz3NGVwmY9k5r86FetgaKlyXyoz76cM5bty\ny7xTogwLO6qWzhcAtqAM/DFktXaKq4n8Zcrtmh+hjM9/DLBpRLwAvJ0y2JU0R9imrq4R5cYtnwPe\nl10wPvb01EtnjqfURq8jTS4AAAXSSURBVCxFuVa5UaW4iBiWZXz6bYAPU0ZwfJlS5f5LyqWH4yl3\nW3tvZt5eX7fQUO7l36uX+yL8//buLNauKY7j+PeHlEaJITE/EBWCGnLRCI0xkZJUUEp4ETHHQxFE\nRAxBDCEigsaU0BpSOiQoqVRbEiUoHZLWLErrRaso0fbnYa3DUTFc7u25Z9/fJ7np2atn77NOH/q/\na+//+v9LY53VksZQHqtcCiwEjqBUApxm+6OOTTgGnQT1GPBqdbhxlGIQ47px7+iGasLYK8BONdFq\naBMCu9r6DKiUun0UOMf2W3Vsa0pQXwGMAK6rq/Tfat53A5We50cCu1M6Ic4CeiglR2+xPblzs4vB\nLLffoxuspGxbO7kpqx7bM+tWtlmSjumGZ8j/RNLelM5dtwNfURq0TAQWSbqI8sx8se0TVBqYbGv7\ni7r6HdABXVIPZVvaUkr99jMojwpGA8dSer0/VL/XeEkvAz8M9O8VzZPs9xjwbK+x/UJTAnqLS/vK\na4EZkjbphozvv1Krwz0NzLe9rN6inkbpSvYiZeva9cABkg6yvdr2FzDw64bXX74epTR/GkbJgVhi\n+zvbzwCTgSsk7W37aWpp0QT06ISs1CM6yPY0Sa92cwCo2foTgRttT5W0KaVl6gRKAxPbXl4D/zaU\nIkJdQdJRwL2UvId5dWwJcKKkkbbnuTTdmUupK7BkIOcERPMlqEd0WAOCwHbAgban1uMZlBX7L8DX\nKkZTqgJe4S6p5V71APfZnidpM5fmMp9StlSeKmkUpfHM0ZTWqhEdlaAeEf+L7dclnVT3nX8CzLF9\nU9tbtqvj59mevWHd+4GobY57AKvq8Lqa0LdK0p2UTPd9KAVmxtQCQhEdlez3iOgTKj2oXwaGtB4n\nqHSeuxQY343V1GoVvGuBq22/o9LbfRPbayWNB14APm/VUYjotCTKRUSfsP0qMIaSIY6kvSjP1Sd1\nY0Cv5lFq0o+T1GN7fQ3oZ1I6A65JQI+BJCv1iOhTtb7985Rnz1fWLP+uJWlXSgGd4yilfH8CxgJj\nm1AzIZolQT0i+ly9Fb+17SmdnktfkDSUkjR3PKXRzizbSzs7q4g/S1CPiH7TDUlxEU2SoB4REdEQ\nSZSLiIhoiAT1iIiIhkhQj4iIaIgE9YiIiIZIUI+IiGiIBPWILiVpe0nz689yScvajod0YD6XS9pi\nY39uRPwuW9oiGkDSDcD3tu/aSJ8nyv8f69vGvgT2t71yY8whIv4sK/WIhpE0XNL8tuNrJF1XX78u\n6W5JcyUtlnSIpCmSPqy/GLTOuUrSwvpzWdt1F0p6EHgX2Lnt/eOBHYC5kmZKurB2Mmv9/cWS7qjX\nWCTpCUkLJD1bq7Uh6VBJsyW9I+klSTv28z9VROMkqEcMPmtsjwIeAaYCFwEjgAskbSPpMOBs4DDg\ncOASSQfUc/cFHrF9sO1lrQvavgf4Bhhl+3hgEqXfeKu987nA423XuN/2CEod9QslbQ7cC5xmuwd4\nEri5f75+RHOln3rE4DO9/rkAWGB7BYCkz4DdgFHAc7Z/rONTgSOBV4CPbb/9Tx9ge7WkOcDo2md9\nne3FkoYDn9p+s771SeAC4DVgP2BmubPPpsCXffBdIwaVBPWI5lnLH+/CbVHHWlqtQte3vW4dbwbo\nb679Qy/m8TBwOfAZ8Fjb+IaJPK6f+UG9gxAR/1Fuv0c0z3JgF0nb1mz0k3p5/hzgFElDJQ0DTgbm\n/ovzVgNbtQ5svwHsCZwOPNP2vj0kHVpfn0XpV74Y2LXe+kfSEEn79XLeEYNegnpEw9j+CbiV0vt7\nOiVg9ub8t4Cn6vlvAg/YXvAvTp1AuX0+s21sMjDH9qq2sUXA+ZI+ALYEJtj+mdKj/G5J7wPvASN7\nM++IyJa2iOhHkmYAt9meXY+HA5NtH9TZmUU0U1bqEdHnamGcpcC3rYAeEf0vK/WIiIiGyEo9IiKi\nIRLUIyIiGiJBPSIioiES1CMiIhoiQT0iIqIhfgWY0ghISJyNdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d4c4438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_bar_chart(\"Tumor type\", \"Log Accuracy\", cancer_type,\n",
    "              'log_accuracy_types', 'Improved Cancer Detection By Type (Logistic Regression)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAIVCAYAAADI5GYOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRER0xL8B27kFDmAMwtYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f15a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_bar_chart(\"Tumor type\", \"Forest Accuracy\", cancer_type,\n",
    "              'forest_accuracy_types', 'Improved Cancer Detection By Type (Random Forest)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHwCAYAAAC/hfaiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dc85e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_bar_chart(\"AJCC Stage\", \"Log Accuracy\", cancer_stage,\n",
    "              'log_accuracy_stages', 'Improved Cancer Detection By Stage (Logistic Regression)', rotate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHwCAYAAAC/hfaiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npEIY6pIkFcJQlySpEIa6JEmF+P/X/VPHAIWOuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dbc9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_bar_chart(\"AJCC Stage\", \"Forest Accuracy\", cancer_stage,\n",
    "              'forest_accuracy_stages', 'Improved Cancer Detection By Stage (Random Forest)', rotate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
